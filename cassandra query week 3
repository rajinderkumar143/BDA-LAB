cqlsh> CREATE KEYSPACE library123
   ... WITH replication = {
   ...    'class': 'SimpleStrategy',
   ...    'replication_factor': 1
   ... };
cqlsh> USE library123;
cqlsh:library123> CREATE TABLE Library_Info (
              ...     Stud_Id int,
              ...     Book_Id int,
              ...     Stud_Name text,
              ...     Book_Name text,
              ...     Date_of_issue date,
              ...     PRIMARY KEY (Stud_Id, Book_Id)
              ... );
cqlsh:library123> CREATE TABLE Library_Counter (
              ...     Stud_Id int,
              ...     Book_Name text,
              ...     Counter_value counter,
              ...     PRIMARY KEY (Stud_Id, Book_Name)
              ... );
cqlsh:library123> BEGIN BATCH
              ... 
              ... INSERT INTO Library_Info (Stud_Id, Book_Id, Stud_Name, Book_Name, Date_of_issue)
              ... VALUES (112, 101, 'Rahul', 'BDA', '2026-02-20');
              ... 
              ... INSERT INTO Library_Info (Stud_Id, Book_Id, Stud_Name, Book_Name, Date_of_issue)
              ... VALUES (113, 102, 'Anita', 'DBMS', '2026-02-21');
              ... 
              ... APPLY BATCH;
cqlsh:library123> UPDATE Library_Counter
              ... SET Counter_value = Counter_value + 1
              ... WHERE Stud_Id = 112 AND Book_Name = 'BDA';
cqlsh:library123> 
cqlsh:library123> UPDATE Library_Counter
              ... SET Counter_value = Counter_value + 1
              ... WHERE Stud_Id = 112 AND Book_Name = 'BDA';
cqlsh:library123> DESCRIBE TABLE Library_Info;

CREATE TABLE library123.library_info (
    stud_id int,
    book_id int,
    book_name text,
    date_of_issue date,
    stud_name text,
    PRIMARY KEY (stud_id, book_id)
) WITH CLUSTERING ORDER BY (book_id ASC)
    AND additional_write_policy = '99p'
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND cdc = false
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND memtable = 'default'
    AND crc_check_chance = 1.0
    AND default_time_to_live = 0
    AND extensions = {}
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair = 'BLOCKING'
    AND speculative_retry = '99p';
cqlsh:library123> DESCRIBE TABLE Library_Counter;

CREATE TABLE library123.library_counter (
    stud_id int,
    book_name text,
    counter_value counter,
    PRIMARY KEY (stud_id, book_name)
) WITH CLUSTERING ORDER BY (book_name ASC)
    AND additional_write_policy = '99p'
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND cdc = false
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND memtable = 'default'
    AND crc_check_chance = 1.0
    AND default_time_to_live = 0
    AND extensions = {}
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair = 'BLOCKING'
    AND speculative_retry = '99p';
cqlsh:library123> SELECT * FROM Library_Info;

 stud_id | book_id | book_name | date_of_issue | stud_name
---------+---------+-----------+---------------+-----------
     113 |     102 |      DBMS |    2026-02-21 |     Anita
     112 |     101 |       BDA |    2026-02-20 |     Rahul

(2 rows)
cqlsh:library123> SELECT * FROM Library_Counter;

 stud_id | book_name | counter_value
---------+-----------+---------------
     112 |       BDA |             2

(1 rows)
cqlsh:library123> UPDATE Library_Counter
              ... SET Counter_value = Counter_value + 1
              ... WHERE Stud_Id = 112 AND Book_Name = 'BDA';
cqlsh:library123> SELECT Counter_value
              ... FROM Library_Counter
              ... WHERE Stud_Id = 112 AND Book_Name = 'BDA';

 counter_value
---------------
             3

(1 rows)
cqlsh:library123> COPY Library_Info TO 'library_info.csv' WITH HEADER = TRUE;
Using 16 child processes

Starting copy of library123.library_info with columns [stud_id, book_id, book_name, date_of_issue, stud_name].
Processed: 2 rows; Rate:      38 rows/s; Avg. rate:      38 rows/s
2 rows exported to 1 files in 0.068 seconds.
cqlsh:library123> COPY Library_Counter TO 'library_counter.csv' WITH HEADER = TRUE;
Using 16 child processes

Starting copy of library123.library_counter with columns [stud_id, book_name, counter_value].
Processed: 1 rows; Rate:      15 rows/s; Avg. rate:      15 rows/s
1 rows exported to 1 files in 0.082 seconds.
cqlsh:library123> COPY Library_Info (Stud_Id, Book_Id, Stud_Name, Book_Name, Date_of_issue)
              ... FROM 'library_info.csv'
              ... WITH HEADER = TRUE;
Using 16 child processes

Starting copy of library123.library_info with columns [stud_id, book_id, stud_name, book_name, date_of_issue].
Failed to import 1 rows: ParseError - Failed to parse Anita : time data 'Anita' does not match format '%Y-%m-%d',  given up without retries
Failed to import 1 rows: ParseError - Failed to parse Rahul : time data 'Rahul' does not match format '%Y-%m-%d',  given up without retries
Failed to process 2 rows; failed rows written to import_library123_library_info.err
Processed: 2 rows; Rate:       4 rows/s; Avg. rate:       6 rows/s
0 rows imported from 1 files in 0.358 seconds (0 skipped).
cqlsh:library123> 
cqlsh:library123> COPY Library_Counter (Stud_Id, Book_Name, Counter_value)
              ... FROM 'library_counter.csv'
              ... WITH HEADER = TRUE;
Using 16 child processes

Starting copy of library123.library_counter with columns [stud_id, book_name, counter_value].
Processed: 1 rows; Rate:       2 rows/s; Avg. rate:       3 rows/s
1 rows imported from 1 files in 0.377 seconds (0 skipped).
